{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abe/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# datasets \n",
    "from sklearn.datasets import load_digits \n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# data processing\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# implemtation\n",
    "import numpy as np\n",
    "import numpy.random as r \n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect\n",
    "\n",
    "def load_mnist_data(source=\"sk\"):\n",
    "    if source == \"sk\":\n",
    "        digits=load_digits()\n",
    "        X = digits.data\n",
    "        y = digits.target\n",
    "    else:\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "        X = np.append(x_train, x_test, axis=0)\n",
    "        X = X.reshape(-1, X.shape[1]**2)\n",
    "        y = np.append(y_train, y_test, axis=0)\n",
    "        \n",
    "    X_scale = StandardScaler()\n",
    "    X = X_scale.fit_transform(X)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.4)\n",
    "    \n",
    "    y_train = convert_y_to_vect(y_train)\n",
    "#     y_test = convert_y_to_vect(y_test)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Implementation\n",
    "\n",
    "We have minified the implementation done in our homework and adapted it suit our needs for running the desired set of hyperparameter combinations and easily add extension modules to our naive implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializers(nn_structure, acti=\"relu\", mode=\"weights\"):\n",
    "    W = {}; b = {};\n",
    "    dW = {}; db = {};\n",
    "    VdW = {}; Vdb = {};\n",
    "    SdW = {}; Sdb = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        if mode==\"weights\":\n",
    "            [low, high, inter] = [0., 1., 0.]\n",
    "            if acti==\"sigmoid\":\n",
    "                inter = np.sqrt((6)/(nn_structure[l] + nn_structure[l-1]))\n",
    "            elif acti==\"relu\":\n",
    "                inter = np.sqrt((6.)/float(nn_structure[l] + nn_structure[l-1]))\n",
    "\n",
    "            W[l] = r.uniform(low=-inter, high=inter, size=(nn_structure[l], nn_structure[l-1])) \n",
    "            b[l] = r.uniform(low=-inter, high=inter, size=(nn_structure[l],))\n",
    "        elif mode==\"gradients\":\n",
    "            dW[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "            db[l] = np.zeros((nn_structure[l],))\n",
    "        elif mode==\"momentum\": \n",
    "            VdW[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "            Vdb[l] = np.zeros((nn_structure[l],))\n",
    "        elif mode==\"rms_prop\": \n",
    "            SdW[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "            Sdb[l] = np.zeros((nn_structure[l],))\n",
    "    if mode==\"weights\":\n",
    "        return W, b\n",
    "    elif mode==\"gradients\":\n",
    "        return dW, db\n",
    "    elif mode==\"momentum\":\n",
    "        return VdW, Vdb\n",
    "    elif mode==\"rms_prop\":\n",
    "        return SdW, Sdb\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def regularizers(W, lamda, mode=\"l2\"):\n",
    "    if mode == \"l2\":\n",
    "        l2_cost = 0.\n",
    "        for l in range(1, len(W)):\n",
    "            l2_cost += np.sum(np.square(W[l]))\n",
    "        return (lamda/2.)*l2_cost\n",
    "    return 0\n",
    "\n",
    "\n",
    "def f(z, activation=\"relu\", deri=False):\n",
    "    if deri:\n",
    "        fz_d = 0\n",
    "        if activation == \"sigmoid\":\n",
    "            fz_d = f(z, activation=\"sigmoid\") * (1 - f(z, activation=\"sigmoid\"))\n",
    "        elif activation == \"relu\":\n",
    "            fz_d = (z>=0).astype(\"int\")\n",
    "        return fz_d\n",
    "    else:\n",
    "        fz = 0\n",
    "        if activation == \"sigmoid\":\n",
    "            fz = 1 / (1 + np.exp(-z))\n",
    "        elif activation == \"relu\":\n",
    "            fz = np.maximum(0, z)\n",
    "        return fz\n",
    "\n",
    "\n",
    "def forward_prop(x, W, b, acti=\"relu\"):\n",
    "    a = {1: x}\n",
    "    z = {} \n",
    "    for l in range(1, len(W) + 1):\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]  \n",
    "        a[l+1] = f(z[l+1], activation=acti) \n",
    "    return a, z\n",
    "\n",
    "\n",
    "def back_prop(y, a, z, W, b, dW, db, acti=\"relu\", regularizer=[0.01, \"l2\"]):\n",
    "    delta = {}\n",
    "    cost = 0\n",
    "    for l in range(len(a), 0, -1):\n",
    "        if l == len(a):\n",
    "            delta[l] = -(y-a[l]) * f(z[l], activation=acti, deri=True) \n",
    "            cost = np.linalg.norm((y-a[l]))\n",
    "            if regularizer and len(regularizer) == 2:\n",
    "                 cost += regularizers(W,regularizer[0],mode=regularizer[1])\n",
    "        else:\n",
    "            if l > 1:\n",
    "                delta[l] = np.dot(np.transpose(W[l]), delta[l+1]) * f(z[l], activation=acti, deri=True)\n",
    "                \n",
    "            dW[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))\n",
    "            db[l] += delta[l+1]\n",
    "    return dW, db, cost\n",
    "\n",
    "\n",
    "def plot_cost(cost):\n",
    "    plt.plot(cost)\n",
    "    plt.ylabel('Average J')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_prop(SdW, dW, Sdb, db, beta2=0.999):\n",
    "    for l in range(1, len(dW)+1):\n",
    "        SdW[l] = beta2*SdW[l] + (1.-beta2)*(dW[l]**2)\n",
    "        Sdb[l] = beta2*Sdb[l] + (1.-beta2)*(db[l]**2)\n",
    "    return SdW, Sdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(nn_structure, X, y, params, verbose=0):\n",
    "    [ext, activation, batch_size, epochs, alpha, reg] = params\n",
    "    cnt = 1\n",
    "    N = len(y)\n",
    "    if not batch_size:\n",
    "        batch_size = N\n",
    "    avg_cost_func = []\n",
    "    if verbose==1:\n",
    "        print('Starting gradient descent for {} iterations\\n\\n'.format(epochs))    \n",
    "    while cnt <= epochs:\n",
    "        if verbose==1:\n",
    "            print('Epoch {} of {}\\n'.format(cnt, epochs))\n",
    "        \n",
    "        if cnt == 1:\n",
    "             W, b = initializers(nn_structure, acti=activation, mode=\"weights\")\n",
    "        epoch_cost = 0 \n",
    "        for j in range(0, N, batch_size):\n",
    "            avg_cost = 0        \n",
    "            dW, db = initializers(nn_structure, acti=activation, mode=\"gradients\")\n",
    "            if ext and ext[\"name\"] == \"rms_prop\":\n",
    "                SdW, Sdb = initializers(nn_structure, mode=\"rms_prop\")\n",
    "\n",
    "            for i in range(j, min(j+batch_size,N), 1):\n",
    "                a, z = forward_prop(X[i, :], W, b, acti=activation)\n",
    "                dW, db, cost = back_prop(y[i,:], a, z, W, b, dW, db, acti=activation, regularizer=reg)\n",
    "                avg_cost += cost\n",
    "                if ext and ext[\"name\"] == \"rms_prop\":\n",
    "                    SdW, Sdb = rms_prop(SdW, dW, Sdb, db, ext[\"params\"][\"beta2\"])\n",
    "\n",
    "            for l in range(len(nn_structure) - 1, 0, -1):\n",
    "                if ext and ext[\"name\"] == \"rms_prop\":\n",
    "                    W[l] += -alpha * (1.0/batch_size * (dW[l]/(np.sqrt(SdW[l]) + ext[\"params\"][\"epsilon\"])) + reg[0]*W[l])\n",
    "                    b[l] += -alpha * (1.0/batch_size * (db[l]/(np.sqrt(Sdb[l]) + ext[\"params\"][\"epsilon\"])))\n",
    "                else:\n",
    "                    W[l] += -alpha * (1.0/batch_size * dW[l] + reg[0]*W[l])\n",
    "                    b[l] += -alpha * (1.0/batch_size * db[l])\n",
    "\n",
    "            avg_cost = 1.0/batch_size * avg_cost\n",
    "            epoch_cost += avg_cost\n",
    "            \n",
    "        avg_cost_func.append(epoch_cost/float(N/batch_size))\n",
    "        cnt += 1\n",
    "    if verbose>=1:\n",
    "        plot_cost(avg_cost_func)\n",
    "    return W, b, avg_cost_func\n",
    "\n",
    "\n",
    "def evaluate(X, y, W, b, n_layers, verbose=0):\n",
    "    N = X.shape[0]\n",
    "    y_pred = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = forward_prop(X[i, :], W, b)\n",
    "        y_pred[i] = np.argmax(a[n_layers])\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print('Prediction accuracy = {:0.2f} %'.format(accuracy * 100))\n",
    "    return accuracy\n",
    "    \n",
    "    \n",
    "def compile_nn(source=\"sk\", ext=None, lr=0.1, num_runs=1, batch_size=None, epochs=300, verbose=2):\n",
    "    nn_structure = [64 if source==\"sk\" else 784, 30, 10]\n",
    "    params = [ext, \"relu\", batch_size, epochs, lr, [0.01,\"l2\"]]\n",
    "    [_, activation,_, epochs, alpha, reg] = params\n",
    "    \n",
    "    if verbose>=1:\n",
    "        print(\"\\n---------------------------\\n\")\n",
    "        print(\"Training Nerual Network with - \\n\\nStructure - {}\\nExtension - {}\\nActivation Function - {}\\nBatch Size - {}\\nEpochs - {}\\nLearning Rate - {}\\nRegularization - {}\".format(nn_structure, ext if ext else \"Naive\", activation, batch_size if batch_size else \"Full\", epochs, alpha, reg))\n",
    "        print(\"\\n---------------------------\\n\")\n",
    "    elif ext:\n",
    "        print(\"Training with extension - {}\".format(ext))\n",
    "    \n",
    "    avg_accuracy = []\n",
    "    \n",
    "    for i in range(1, num_runs+1):\n",
    "        (X_train, y_train), (X_test, y_test) = load_mnist_data(source)\n",
    "        W, b, avg_cost_func = train(nn_structure, X_train, y_train, params, verbose)\n",
    "        avg_accuracy.append(evaluate(X_test, y_test, W, b, 3, verbose))\n",
    "    \n",
    "    if num_runs > 1:\n",
    "        print(\"Average accuracy over {} runs = {:0.2f} %\".format(num_runs, (np.sum(np.array(avg_accuracy))/float(num_runs)*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn MNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy = 88.32 %\n",
      "Prediction accuracy = 87.62 %\n",
      "Prediction accuracy = 86.93 %\n",
      "Prediction accuracy = 98.33 %\n",
      "Prediction accuracy = 79.83 %\n",
      "Average accuracy over 5 runs = 88.21 %\n"
     ]
    }
   ],
   "source": [
    "compile_nn(source=\"sk\", ext=None, num_runs=5, batch_size=32, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with extension - {'name': 'rms_prop', 'params': {'beta2': 0.9, 'epsilon': 1e-07}}\n",
      "Prediction accuracy = 85.67 %\n",
      "Prediction accuracy = 84.28 %\n",
      "Prediction accuracy = 94.99 %\n",
      "Prediction accuracy = 86.51 %\n",
      "Prediction accuracy = 84.70 %\n",
      "Average accuracy over 5 runs = 87.23 %\n"
     ]
    }
   ],
   "source": [
    "ext={\"name\":\"rms_prop\", \"params\":{\"beta2\":0.9, \"epsilon\":1e-7}}\n",
    "compile_nn(source=\"sk\", ext=ext, lr=0.01, num_runs=5, batch_size=32, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow MNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy = 82.82 %\n",
      "Prediction accuracy = 93.27 %\n",
      "Prediction accuracy = 82.38 %\n",
      "Prediction accuracy = 82.69 %\n",
      "Prediction accuracy = 93.20 %\n",
      "Average accuracy over 5 runs = 86.87 %\n"
     ]
    }
   ],
   "source": [
    "compile_nn(source=\"tf\", ext=None, num_runs=5, batch_size=512, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with extension - {'name': 'rms_prop', 'params': {'beta2': 0.9, 'epsilon': 1e-07}}\n",
      "Prediction accuracy = 90.66 %\n",
      "Prediction accuracy = 90.74 %\n",
      "Prediction accuracy = 80.56 %\n",
      "Prediction accuracy = 82.78 %\n",
      "Prediction accuracy = 91.07 %\n",
      "Average accuracy over 5 runs = 87.16 %\n"
     ]
    }
   ],
   "source": [
    "ext={\"name\":\"rms_prop\", \"params\":{\"beta2\":0.9, \"epsilon\":1e-7}}\n",
    "compile_nn(source=\"tf\", ext=ext, lr=0.1, num_runs=5, batch_size=512, epochs=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
